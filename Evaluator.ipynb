{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "import sklearn\n",
    "import os\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from BeautifulSoup import BeautifulSoup\n",
    "\n",
    "# PREPROCESS XML DOCUMENTS\n",
    "def extract_from_xml(xml):\n",
    "    bs = BeautifulSoup(xml)\n",
    "    # tab na pocetku\n",
    "    return [document.text.rstrip('\\t') for document in bs.findAll('document')]\n",
    "\n",
    "\n",
    "def remove_special_data(text):\n",
    "    # TODO if needed\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strukture za pohranu dataseta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LABELS = ['userid', 'gender', 'age_group',\n",
    "          'extroverted', 'stable', 'agreeable',\n",
    "          'conscientious', 'open']\n",
    "\n",
    "''' User class used to store parsed data'''\n",
    "class User(object):\n",
    "\n",
    "    def __init__(self, line):\n",
    "        self.labels = LABELS\n",
    "\n",
    "        parts = map(str.strip, line.split(FIELDS_DELIMITER))\n",
    "        if len(parts) == 1:\n",
    "            parts = [parts[0]] + [''] * 7\n",
    "\n",
    "        self.userid = parts[0]\n",
    "        self.gender = parts[1]\n",
    "        self.age_group = parts[2]\n",
    "\n",
    "        self.extroverted = parts[3]\n",
    "        self.stable = parts[4]\n",
    "        self.agreeable = parts[5]\n",
    "        self.conscientious = parts[6]\n",
    "        self.open = parts[7]\n",
    "        self.documents = []\n",
    "\n",
    "    def user_details(self):\n",
    "        return [self.userid, self.gender,\n",
    "                self.age_group, self.extroverted, self.stable,\n",
    "                self.agreeable, self.conscientious, self.open]\n",
    "\n",
    "    def user_documents(self):\n",
    "        return self.documents\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRUTH_FILE = 'truth.txt'\n",
    "FIELDS_DELIMITER = ':::'\n",
    "LABELS = ['userid', 'gender', 'age_group',\n",
    "          'extroverted', 'stable', 'agreeable',\n",
    "          'conscientious', 'open']\n",
    "\n",
    "'''Dataset wrapper - parses, cleans and stores user data (documents and truth)\n",
    "'''\n",
    "class Dataset(object):\n",
    "\n",
    "    def __init__(self, path):\n",
    "        if not os.path.exists(path) or not os.path.isdir(path):\n",
    "            raise Exception('No such dir ' + path)\n",
    "\n",
    "        self.path = path\n",
    "        self.users = {}\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        self.load()\n",
    "        self.labels = LABELS\n",
    "\n",
    "    def load(self):\n",
    "        user_files = filter(lambda name: name != TRUTH_FILE, os.listdir(self.path))\n",
    "        truth = os.path.join(self.path, TRUTH_FILE)\n",
    "        assert os.path.isfile(truth)\n",
    "\n",
    "        # load truth\n",
    "        with open(truth, 'r') as f:\n",
    "            for line in f:\n",
    "                user = User(line)\n",
    "                self.users[user.userid] = user\n",
    "\n",
    "        # load texts\n",
    "        for path in user_files:\n",
    "            user = os.path.splitext(path)[0]\n",
    "            path = os.path.join(self.path, path)\n",
    "\n",
    "            with open(path, 'r') as xml:\n",
    "                content = extract_from_xml(xml.read())\n",
    "                if not self.users.has_key(user):\n",
    "                    self.users[user] = User(user)\n",
    "                self.users[user].documents = map(remove_special_data, content)\n",
    "\n",
    "    def store_as_samples(self):\n",
    "        for id, user in self.users.items():\n",
    "            self.X.append('\\n'.join(user.documents))\n",
    "            self.y.append(np.array(user.user_details()))\n",
    "\n",
    "        self.X = np.array(self.X)\n",
    "        self.y = np.array(self.y)\n",
    "\n",
    "    def get_samples(self, feature='all'):\n",
    "        if feature == 'all':\n",
    "            return self.X, self.y\n",
    "\n",
    "        feature_col = [i for i, lab in enumerate(self.labels) if lab == feature]\n",
    "        if len(feature_col):\n",
    "            feature_col = feature_col[0]\n",
    "        else:\n",
    "            raise Exception('Invalid feature %s\\nValid features %s' %\n",
    "                            (feature, ', '.join(self.labels)))\n",
    "\n",
    "        return self.X, self.y[:, feature_col]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pomocni razredi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "'''Transformes sparse matrix to dense - ex. for NaiveBayes'''\n",
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#simple demo\n",
    "\n",
    "dataset_path = './dataset/english'\n",
    "d = Dataset(dataset_path)\n",
    "d.store_as_samples() #transforme data to X, y\n",
    "\n",
    "X, y = d.get_samples('age_group')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC training score 0.993421052632\n",
      "Bayes training score 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import  GaussianNB\n",
    "from sklearn.pipeline import  Pipeline \n",
    "\n",
    "\n",
    "vectorize = TfidfVectorizer(analyzer='char', ngram_range=(3,3))\n",
    "svcPipe = Pipeline([('vectorize', vectorize), ('densen', DenseTransformer()), ('svc', LinearSVC())])\n",
    "bayesPipe = Pipeline([('vectorize', vectorize), ('densen', DenseTransformer()), ('bayes', GaussianNB())])\n",
    "\n",
    "svcPipe.fit(X, y)\n",
    "print 'SVC training score %s' % svcPipe.score(X, y)\n",
    "                    \n",
    "\n",
    "bayesPipe.fit(X, y)\n",
    "print 'Bayes training score %s' % bayesPipe.score(X, y)\n",
    "\n",
    "# without pipeline\n",
    "#vectorize = TfidfVectorizer(analyzer='char', ngram_range=(3,3))\n",
    "#X = vectorize.fit_transform(X)\n",
    "#model = LinearSVC()\n",
    "#model.fit(X,y)\n",
    "#print model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# below code taken and adapted from example\n",
    "# @ http://scikit-learn.org/stable/auto_examples/plot_learning_curve.html\n",
    "from sklearn.learning_curve import learning_curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 10)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and traning learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : integer, cross-validation generator, optional\n",
    "        If an integer is passed, it is the number of folds (defaults to 3).\n",
    "        Specific cross-validation objects can be passed, see\n",
    "        sklearn.cross_validation module for the list of possible objects\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix,precision_recall_curve\n",
    "\n",
    "\n",
    "#TODO jos dodati ovaj precision_recall_curve, pokazivali na predavanjima cini se korisno\n",
    "def printScore(y_true,y_pred,average='micro'):\n",
    "    print average+\" scores:\"\n",
    "    print \"\\t P  = %s\" % precision_score(y_true,y_pred,average=average)\n",
    "    print \"\\t R  = %s\" % recall_score(y_true,y_pred,average=average)\n",
    "    print \"\\t F1 = %s\" % f1_score(y_true,y_pred,average=average)\n",
    "\n",
    "\n",
    "def modelEvaluator(X, y, model, parameters, scoring = None, num_flods = 3,test_size = 0.3,ylim=None,train_sizes_lncurv=np.linspace(.1, 1.0, 10)):\n",
    "   \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    \n",
    "    grid_cv = GridSearchCV( model, parameters, scoring = scoring, n_jobs = -1, verbose = 1, cv = num_flods)\n",
    "    grid_cv.fit(X_train,y_train)\n",
    "    \n",
    "    print 'Model best_params: %s' % grid_cv.best_params_\n",
    "    estimator = grid_cv.best_estimator_\n",
    "    print 'Model acc : %s' % estimator.score(X_test,y_test)\n",
    "    \n",
    "    y_pred = estimator.predict(X_test)\n",
    "    \n",
    "    print \"Confusion matrix:\\n %s\" % confusion_matrix(y_test,y_pred)\n",
    "    \n",
    "    #TODO trebaju biti binarne, problem onda treba minjati OVO i OVR \n",
    "    #precision, recall, _ = precision_recall_curve(y_test.ravel(), y_pred.ravel())\n",
    "    #plt.plot(precision,recall)\n",
    "    \n",
    "    if scoring == None:\n",
    "            printScore(y_test,y_pred,'macro')\n",
    "            printScore(y_test,y_pred)\n",
    "    \n",
    "    plot_learning_curve(estimator, \"Test\", X, y,  ylim=ylim, cv=num_flods,train_sizes=train_sizes_lncurv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of  12 | elapsed:    0.1s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  12 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model best_params: {'kernel': 'linear', 'C': 10000000}\n",
      "Model acc : 0.97962962963\n",
      "Confusion matrix:\n",
      " [[53  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 49  0  0  0  0  0  0  1  0]\n",
      " [ 0  0 47  0  0  0  0  0  0  0]\n",
      " [ 0  0  1 52  0  1  0  0  0  0]\n",
      " [ 0  1  0  0 59  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 64  0  1  0  1]\n",
      " [ 0  0  0  0  0  0 53  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 54  0  1]\n",
      " [ 0  0  0  0  0  1  0  0 42  0]\n",
      " [ 0  0  0  0  1  0  0  1  1 56]]\n",
      "macro scores:\n",
      "\t P  = 0.979654537991\n",
      "\t R  = 0.980370817623\n",
      "\t F1 = 0.979939123433\n",
      "micro scores:\n",
      "\t P  = 0.97962962963\n",
      "\t R  = 0.97962962963\n",
      "\t F1 = 0.97962962963\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'plot_learning_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-28dbe9036fc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'kernel'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rbf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'C'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10000000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodelEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-f1ec565df822>\u001b[0m in \u001b[0;36mmodelEvaluator\u001b[1;34m(X, y, model, parameters, scoring, num_flods, test_size, ylim, train_sizes_lncurv)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mprintScore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mplot_learning_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Test\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mylim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mylim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_flods\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_sizes_lncurv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: global name 'plot_learning_curve' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[0.001, 10000000]}\n",
    "model = svm.SVC()\n",
    "modelEvaluator(X, y, model, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(set(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
