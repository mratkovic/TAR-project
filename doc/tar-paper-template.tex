% Tenplate for TAR 2014
% (C) 2014 Jan Šnajder, Goran Glavaš
% KTLab, FER

\documentclass[10pt, a4paper]{article}

\usepackage{tar2014}

\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}

\usepackage[activate={true,nocompatibility},final,tracking=true,kerning=true,spacing=true,factor=1100,stretch=10,shrink=10]{microtype}

\title{Author profiling}

%VAŽNO: Zakomentirajte sljedeću liniju kada šaljete rad na recenziju
\name{Lovre Mrčela, Marko Ratković, Ante Žužul} 

\address{
University of Zagreb, Faculty of Electrical Engineering and Computing\\
Unska 3, 10000 Zagreb, Croatia\\ 
\texttt{\{lovre.mrcela, marko.ratkovic, ante.zuzul\}@fer.hr}\\
}
          
         
\abstract{ 
The goal of this project was to profile an author by analyzing a set of texts written by them, and then determining degree of each the Big Five personality traits.
In addition, gender and age--group for each author are derived as well.
The dataset was collected from twitter profiles, in English, Italian, Spanish and Dutch languages.
Approach was based on \textit{tf-idf}, considering occurences of trigrams.
The implementation is done in Pythong programming language, using \textit{nltk} and \textit{sklearn} libraries.
}

\begin{document}

\maketitleabstract

\section{Introduction}

Author profiling deals with problem of describing someone's personality, by means of extracting information from their writing style.
Personality can be described using five traits (the so-called \textit{``Big Five personality traits''}), which are: extraversion, stability, agreeableness, conscientiousness and openness to experience.
Degrees of each trait range from -0.5 (indicating the total opposite), to 0.5 (indicating the exact match).

Provided with degrees of the five traits, it is possible to determine author's gender and age--group, via classification based on a model trained on previously labelled data.
In this project, we used the linear SVC and Gaussian naive Bayes models for the classification into gender and age--group, and the linear regression with squared error measure for determining the degrees of personality traits.
The training set we used was a collection of twitter posts in English, Spanish, Italian and Dutch authors, ranging from around 35 authors in Dutch to 150 in English, each author's file containing about 100 posts.

\section{Approach}

In this section, the methods of our approach are thoroughly explained.
First, the preprocessing of input text is carried out, and weighted vector of trigrams (three consecutive letters) is obtained.
Then, from preprocessed text some additional feature vectors, which were reasonably expected to be discriminative, are extracted.
Finally, gender and age--group classification and personality traits regression models are trained on extracted features, and final results are compared for various parameters.

\subsection{Text preprocessing}

For the rest of the process to be optimal, some sort of text preprocessing needs to be done on the raw input data.
The input data we use is given in \textit{xml} format, so the first step in preprocessing was to parse the actual sentences from the \textit{xml} structure.
When that is done, following steps are also applied:
\begin{itemize}
	\item \textit{urls} to other sites are substituted with an \textsc{url} tag, and usernames (when referenced in replies) are substituted with a \textsc{reply} tag,
	\item all the text is converted to lower case because we don't deal with capitalization of words, only with words themselves;
	\item more than 3 repetitions of the same letter are reduced to 3 letters, so that the words like \textit{``coooool''} (5 repetitions) and \textit{``coooooool''} (7 repetitions) are both treated as the same word, but distinctly from \textit{``cool''}, because while we want to take repetitions into account, we would like to ignore the quantity of repeated letters (see the Section \ref{sec:features});
	\item stop words (for that particular language) are deleted from the text, because they are considered unsignificant for author profiling.
\end{itemize}

Each three consecutive letters are grouped into trigrams, and weighted vector of trigrams is obtained, using \textit{tf--idf} weighting scheme.
The extracted trigram weighted vector is used as one feature.
More features are then extracted from preprocessed text, as described in the next subsection.

\subsection{Additional feature extraction}
\label{sec:features}
In addition to weighted vector of trigrams, we decided to investigate some further characteristics of the written corpora, which were expected to be discriminative for the gender and/or age--group.
Here is the list of cosidered additional features, and explanation for each of them:

\begin{itemize}
	\item \textbf{number of emoticons:} the average number of emoticons used in a post (e.g. \verb|:)|, \verb|<3|; not considering each emoticon distinctly but all of them in total),
	\item \textbf{number of consecutive long repetitions of letters:} as mentioned before, we count only occurences of repetitions longer than 3 letters, not the length of repetitions themselves -- these repetitions most of the time do not have constant number of letters, even for the same author, or the same post, so it is a better approach to take into account only instances of repetitions;
	\item \textbf{number of replies:} the average number of replies to another user per each post,
	\item \textbf{number of hashtags:} the average number of hashtags per post,
	\item \textbf{number of exclamation marks:} the average number of exclamation marks (\verb|!|) per post -- each exclamation marks is counted, as we considered that, opposed to the consecutive repetition of letters, repeated exclamation marks do indicate author's stronger emotion to a some degree.
	\item \textbf{average length and standard deviation of posts:} we were inspecting average post length, as we presume it may also be correlated with age--groups;
	\item \textbf{average length and standard deviation of words:} as above, but considering just words.
\end{itemize}

It was expected for some of the features to be present in a greater degree in some subpopulations compared to the other (i.e. younger vs. older, male vs. female).
The obtained results respective to each feature are shown in the section \ref{sec:results}.

\subsection{Gender and age--group classification}

For the gender and age--group classification subproblem, following approaches were considered:
\begin{itemize}
	\item Logistic Regression
	\item Naive Bayes Classifier
	\item Decision Tree Classifier
	\item Random Forest Classifier
	\item SVC (using \textit{rbf}, linear, poly- and sigmoid kernels)
\end{itemize}
\noindent The best result was obtained by using SVC with linear kernel, compared to other methods.

\subsection{Personality traits regression}
For the personality traits regression, following approaches were considered:
\begin{itemize}
	\item Linear Regression
	\item Decision Tree Regressor
	\item Random Forest Regressor
	\item SVR (using various kernels)
\end{itemize}
\noindent After testing each method, the best results turn out to be obtained by using SVR and linear regression.

\section{Testing}
Due to the lack of access to the official testing dataset (because of an ongoing competition), the official training dataset was divided into a subset for training (around 70\%) and a subset for testing (around 30\%).

The model hyperparameters for gender and age--group classifiers are optimized using \textit{k--fold} cross--validation.

\section{Results}
\label{sec:results}
For the age--group and gender classification, baseline error is represented as score of Naive Bayes Classifier.
For the personality traits, we defined baseline error as root mean--square error of average of all features.
Precision, recall, F1 micro score, and macro score measures for each language are shown in table \ref{tab:scores}.

\begin{table*}
\caption{Overview of results per language.}
\label{tab:classifiers}
\begin{center}
\begin{tabular}{l|r|r|r||r}
\toprule
Language & Precision & Recall & F1 & Macro score \\
\midrule
\textit{English} & $0.71787$ & $0.64035$ & $0.65214$ & $0.78261$ \\
\textit{Italian} & & & & \\
\textit{Spanish} & & & & \\
\textit{Dutch} & & & & \\
\bottomrule
\end{tabular}
\end{center}
\end{table*}

\section{Conclusion}
Experimenting with various models and features, we obtained results similar to other published works (in our case, tested on reduced training set).
Unfortunately, we were not able to test our solution on the official data due to the data not yet having been released.

The possible upgrade of this work would be researching application of Latent Semantic Indexing, as it may further improve detection of author personal traits.

%\section{Extent of the paper}
%
%The paper should have at least. The paper should have a minimum of 3 and a maximum of 5 pages plus an additional page for references.
%
%\section{Figures and tables}
%
%\subsection{Figures}
%
%Here is an example on how to include figures in the paper. Figures are included in \LaTeX code immediately \textit{after} the text in which these figures are referenced. Allow \LaTeX to place the figure where it believes is best (usually on top of the page of at the position where you would not place the figure). Figures are references as follows: ``Figure~\ref{fig:figure1} shows \dots''. Use tilda (\verb.~.) to prevent separation between the word ``Figure'' and its enumeration. 
%
%\begin{figure}
%\begin{center}
%\includegraphics[width=\columnwidth]{tar1314}
%\caption{This is the figure caption. Full sentences should be followed with a dot. The caption should be placed \textit{below} the figure. Caption should be short; details should be explained in the text.}
%\label{fig:figure1}
%\end{center}
%\end{figure}
%
%\subsection{Tables}
%
%There are two types of tables: narrow tables that fit into one column and a wide table that spreads over both columns.
%
%\subsubsection{Narrow tables}
%
%%An example of the narrows table is the Table~\ref{tab:narrow-table}. Do not use vertical lines in tables -- vertical tables have no effect and they make tables visually less attractive.
%
%\begin{table}
%\caption{Comparison of results obtained by using different classifiers.}
%\label{tab:classifiers}
%\begin{center}
%\begin{tabular}{ll}
%\toprule
%Heading1 & Heading2 \\
%\midrule
%One & First row text \\
%Two   & Second row text \\
%Three   & Third row text \\
%      & Fourth row text \\
%\bottomrule
%\end{tabular}
%\end{center}
%\end{table}
%
%\begin{table}
%	\caption{Comparison of results obtained by using different regressors.}
%	\label{tab:regressors}
%	\begin{center}
%		\begin{tabular}{ll}
%			\toprule
%			Heading1 & Heading2 \\
%			\midrule
%			One & First row text \\
%			Two   & Second row text \\
%			Three   & Third row text \\
%			& Fourth row text \\
%			\bottomrule
%		\end{tabular}
%	\end{center}
%\end{table}
%
%\subsection{Wide tables}
%
%Table~\ref{tab:wide-table} is an example of a wide table that spreads across both columns. The same can be done for wide figures that should spread across the whole width of the page. 
%
%\begin{table*}
%\caption{Wide-table caption}
%\label{tab:wide-table}
%\begin{center}
%\begin{tabular}{llr}
%\toprule
%Heading1 & Heading2 & Heading3\\
%\midrule
%A & A very long text, longer that the width of a single column & $128$\\
%B & A very long text, longer that the width of a single column & $3123$\\
%C & A very long text, longer that the width of a single column & $-32$\\
%\bottomrule
%\end{tabular}
%\end{center}
%\end{table*}
%
%\section{Math expressions and formulas}
%
%Math expressions and formulas that appear within the sentence should be writen inside the so-called \emph{inline} math environment: $2+3$, $\sqrt{16}$, $h(x)=\mathbf{1}(\theta_1 x_1 + \theta_0>0)$. Larger expressions and formulas (e.g., equations) should be written in the so-called \emph{displayed} math environment:
%
%\[
%b^{(i)}_k = \begin{cases}
%1 & \text{ako 
%    $k = \text{argmin}_j \| \mathbf{x}^{(i)} - \mathbf{\mu}_j \|$}\\
%0 & \text{inače}
%\end{cases}
%\]
%
%Math expressions which you reference in the text should be written inside the \textit{equation} environment:
%
%\begin{equation}\label{eq:kmeans-error}
%J = \sum_{i=1}^N \sum_{k=1}^K 
%b^{(i)}_k \| \mathbf{x}^{(i)} - \mathbf{\mu}_k \|^2
%\end{equation}
%
%Now you can reference equation \eqref{eq:kmeans-error}. If the paragraphs continues right after the formula
%
%\begin{equation}
%f(x) = x^2 + \varepsilon
%\end{equation}
%
%\noindent like this one does, then use the command \emph{noindent} after the equation to prevent the indentation of the row starting the paragraph. 
%
%Multiletter words in the math environment should be written inside the command \emph{mathit}, otherwise \LaTeX will insert spacing between the letters to denote the multicplication of values denoted by symbols. For example, compare
%$\mathit{Consistent}(h,\mathcal{D})$ and\\
%$Consistent(h,\mathcal{D})$.
%
%If you need a math symbol, but you don't know the command for it in \LaTeX, try
%\emph{Detexify}.\footnote{\texttt{http://detexify.kirelabs.org/}}
%
%\section{Referencing literature}
%
%References to other publications should be written in brackets with the last name of the first author and the year of publication, e.g., \citep{chomsky-73}.  Multiple references are written in sequence, one after another, separated by semicolon and without whitespaces in between, e.g., \citep{chomsky-73,chave-64,feigl-58}. References are typically written at the end of the sentence and necessarily before the sentence punctuation.
%
%If the publication is authored by more than author, only the name of the first author is written, after which abbreviation \emph{et al.}, meaning \emph{et alia}, i.e.,~and others is written as in \citep{johnson-etc}. If the publication is authored by only two authors, then the last names of both authors are written \citep{johnson-howells}.
%
%If the name of the author is incorporated into the text of the sentence, it should be out of the brackets (only the year should be in the brackets). E.g.,~``\citet{chomsky-73}
%suggested that \dots''. The difference is whether you reference the publication or the author who wrote it. 
%
%The list of all literature references is given alphabetically at the end of the paper. The form of the reference depends on the type of the bibliographic unit: conference papers,
%\citep{chave-64}, books \citep{butcher-81}, journal articles
%\citep{howells-51}, doctoral dissertations \citep{croft-78} and book chapters \citep{feigl-58}. 
%
%All of this is produced for you automatically by using BibTeX. Sve ovo dobivate automatski ako. In the file \texttt{tar2014.bib} insert the BibTeX entries, and then reference them via their symbolic names.
%
%\section{Conclusion}
%
%Conclusion is the last enumerated section of the paper. Conclusion should not exceed half of the column and is typically be split into 2--3 paragraphs.

\bibliographystyle{tar2014}
\bibliography{tar2014} 

\end{document}

